{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpo-FCnNVBp0",
        "outputId": "7556901c-7799-4d60-a843-eefc23b5f6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "krXRRZ2lVGrs",
        "outputId": "5a851277-b920-4e68-bd75-7f2623d1505a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File path: /content/drive/MyDrive/RIM-ONE_DL_images/partitioned_randomly/training_set/0001_0001_0001_0001_0001_0001_0001_0001_0001_0001_0000_0001_0000_0001_0000_0000_0000_0000_0000_normal/r3_N-27-L_left_half.png\n",
            "File not found. Check the file path.\n",
            "File path: /content/drive/MyDrive/RIM-ONE_DL_images/partitioned_randomly/training_set/0001_0000_0001_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0001_0000_0001_0000_0001_0001_0001_0001_0001_glaucoma/r2_Im420.png\n",
            "File not found. Check the file path.\n",
            "Found 311 images belonging to 2 classes.\n",
            "Found 339 images belonging to 2 classes.\n",
            "Found 174 images belonging to 2 classes.\n",
            "Found 339 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ba60d2278ff5>\u001b[0m in \u001b[0;36m<cell line: 135>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m# Create custom combined generators for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mtest_generator_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator_hospital\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m# Combine the generators for both \"partitioned_by_hospital\" and \"partitioned_randomly.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_generator_random' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, UpSampling2D, Concatenate, Cropping2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Add\n",
        "\n",
        "# Verify that the file path you are using is correct.\n",
        "file_path = '/content/drive/MyDrive/RIM-ONE_DL_images/partitioned_randomly/training_set/0001_0001_0001_0001_0001_0001_0001_0001_0001_0001_0000_0001_0000_0001_0000_0000_0000_0000_0000_normal/r3_N-27-L_left_half.png'\n",
        "print(\"File path:\", file_path)\n",
        "\n",
        "# Now attempt to access the file\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        # Your file processing code here\n",
        "        pass\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found. Check the file path.\")\n",
        "\n",
        "# Define your data directories\n",
        "base_dir_hospital = '/content/drive/MyDrive/RIM-ONE_DL_images/partitioned_by_hospital'\n",
        "base_dir_random = '/content/drive/MyDrive/RIM-ONE_DL_images/partitioned_randomly'\n",
        "\n",
        "relative_file_path = '/content/drive/MyDrive/RIM-ONE_DL_images/partitioned_randomly/training_set/0001_0000_0001_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0000_0001_0000_0001_0000_0001_0001_0001_0001_0001_glaucoma/r2_Im420.png'\n",
        "\n",
        "# Convert to an absolute path\n",
        "absolute_file_path = os.path.abspath(relative_file_path)\n",
        "\n",
        "# Verify that the file path you are using is correct.\n",
        "print(\"File path:\", absolute_file_path)\n",
        "\n",
        "# Now attempt to access the file\n",
        "try:\n",
        "    with open(absolute_file_path, \"rb\") as f:\n",
        "        # Your file processing code here\n",
        "        pass\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found. Check the file path.\")\n",
        "\n",
        "# Shuffle the files in the training directories\n",
        "def shuffle_directory(directory):\n",
        "    file_list = os.listdir(directory)\n",
        "    random.shuffle(file_list)\n",
        "    for i, filename in enumerate(file_list):\n",
        "        os.rename(os.path.join(directory, filename), os.path.join(directory, f\"{i:04d}_{filename}\"))\n",
        "\n",
        "# Shuffle the training data directories\n",
        "shuffle_directory(os.path.join(base_dir_hospital, 'training_set'))\n",
        "shuffle_directory(os.path.join(base_dir_random, 'training_set'))\n",
        "\n",
        "# Define a custom generator that shuffles the data\n",
        "def custom_generator(generator1, generator2):\n",
        "    while True:\n",
        "        try:\n",
        "            batch_x1, batch_y1 = next(generator1)\n",
        "        except StopIteration:\n",
        "            generator1 = iter(generator1)  # Restart the generator if it's exhausted\n",
        "            batch_x1, batch_y1 = next(generator1)\n",
        "\n",
        "        try:\n",
        "            batch_x2, batch_y2 = next(generator2)\n",
        "        except StopIteration:\n",
        "            generator2 = iter(generator2)  # Restart the generator if it's exhausted\n",
        "            batch_x2, batch_y2 = next(generator2)\n",
        "\n",
        "        # Shuffle the data within each batch\n",
        "        indices1 = np.arange(len(batch_x1))\n",
        "        np.random.shuffle(indices1)\n",
        "        batch_x1 = batch_x1[indices1]\n",
        "        batch_y1 = batch_y1[indices1]\n",
        "\n",
        "        indices2 = np.arange(len(batch_x2))\n",
        "        np.random.shuffle(indices2)\n",
        "        batch_x2 = batch_x2[indices2]\n",
        "        batch_y2 = batch_y2[indices2]\n",
        "\n",
        "        yield (batch_x1, batch_y1), (batch_x2, batch_y2)\n",
        "\n",
        "# Image dimensions and batch size.\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Create data generators for the \"partitioned_by_hospital\" folder.\n",
        "train_generator_hospital = train_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir_hospital, 'training_set'),\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Change to 'categorical' if you have more than two classes.\n",
        ")\n",
        "\n",
        "# Create data generators for the \"partitioned_randomly\" folder (training set).\n",
        "train_generator_random = train_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir_random, 'training_set'),\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Change to 'categorical' if you have more than two classes.\n",
        ")\n",
        "\n",
        "# Create data generators for the \"partitioned_by_hospital\" folder (test set).\n",
        "test_generator_hospital = test_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir_hospital, 'test_set'),\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Change to 'categorical' if you have more than two classes.\n",
        ")\n",
        "\n",
        "\n",
        "# Create data generators for the \"partitioned_randomly\" folder (training set).\n",
        "train_generator_random = train_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir_random, 'training_set'),\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Change to 'categorical' if you have more than two classes.\n",
        ")\n",
        "\n",
        "# Create custom combined generators for testing\n",
        "test_generator_combined = custom_generator(test_generator_hospital, test_generator_random)\n",
        "\n",
        "# Combine the generators for both \"partitioned_by_hospital\" and \"partitioned_randomly.\"\n",
        "def combined_generator(generator1, generator2):\n",
        "    while True:\n",
        "        try:\n",
        "            batch_x1, batch_y1 = next(generator1)\n",
        "        except StopIteration:\n",
        "            generator1 = iter(generator1)  # Restart the generator if it's exhausted\n",
        "            batch_x1, batch_y1 = next(generator1)\n",
        "\n",
        "        try:\n",
        "            batch_x2, batch_y2 = next(generator2)\n",
        "        except StopIteration:\n",
        "            generator2 = iter(generator2)  # Restart the generator if it's exhausted\n",
        "            batch_x2, batch_y2 = next(generator2)\n",
        "\n",
        "        yield (batch_x1, batch_y1), (batch_x2, batch_y2)\n",
        "\n",
        "train_generator_combined = combined_generator(train_generator_hospital, train_generator_random)\n",
        "test_generator_combined = combined_generator(test_generator_hospital, test_generator_random)\n",
        "\n",
        "# Define the ResU-Net layers (encoder, bottleneck, and decoder).\n",
        "input_tensor = Input(shape=(img_width, img_height, 3))\n",
        "\n",
        "# Encoder\n",
        "encoder_output = Conv2D(64, (3, 3), activation='relu', padding='same')(input_tensor)\n",
        "encoder_output = MaxPooling2D((2, 2))(encoder_output)\n",
        "encoder_output = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = MaxPooling2D((2, 2))(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = MaxPooling2D((2, 2))(encoder_output)\n",
        "\n",
        "# Bottleneck\n",
        "encoder_output = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)  # Adjusted shape\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "bottleneck_output = Add()([x, encoder_output])  # Residual connection\n",
        "\n",
        "# Decoder\n",
        "x = UpSampling2D((2, 2))(bottleneck_output)\n",
        "crop_height = x.shape[1]\n",
        "crop_width = x.shape[2]\n",
        "encoder_output_adjusted_cropped = Cropping2D(cropping=((0, 0), (0, 0)))(encoder_output)\n",
        "encoder_output_adjusted_upsampled = UpSampling2D(size=(2, 2))(encoder_output_adjusted_cropped)\n",
        "x = Concatenate()([x, encoder_output_adjusted_upsampled])  # Skip connection\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "output_tensor = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "# Implement early stopping to prevent overfitting.\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Calculate the number of steps per epoch for training and validation\n",
        "steps_per_epoch_train = len(train_generator_hospital) // batch_size\n",
        "steps_per_epoch_val = len(test_generator_hospital) // batch_size\n",
        "\n",
        "# Debugging: Print some information about the generators and dataset\n",
        "print(\"Train Generator Hospital:\", len(train_generator_hospital), \"batches,\", train_generator_hospital.samples, \"samples\")\n",
        "print(\"Train Generator Random:\", len(train_generator_random), \"batches,\", train_generator_random.samples, \"samples\")\n",
        "print(\"Test Generator Hospital:\", len(test_generator_hospital), \"batches,\", test_generator_hospital.samples, \"samples\")\n",
        "print(\"Test Generator Random:\", len(test_generator_random), \"batches,\", test_generator_random.samples, \"samples\")\n",
        "\n",
        "for (batch_x1, batch_y1), (batch_x2, batch_y2) in train_generator_combined:\n",
        "    print(\"Batch X1 Shape:\", batch_x1.shape)\n",
        "    print(\"Batch Y1 Shape:\", batch_y1.shape)\n",
        "    # Add print statements to display file paths or other relevant information.\n",
        "\n",
        "\n",
        "# Train the model using the custom generators\n",
        "history = model.fit(\n",
        "    train_generator_combined,\n",
        "    steps_per_epoch=steps_per_epoch_train,\n",
        "    epochs=100,\n",
        "    validation_data=test_generator_combined,\n",
        "    validation_steps=steps_per_epoch_val,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the combined test set.\n",
        "test_loss, test_accuracy = model.evaluate(test_generator_combined, steps=steps_per_epoch_val)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "# Plot training history.\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}